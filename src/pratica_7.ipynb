{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.io import loadmat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = loadmat('../data/pratica_7/dadosex2.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'Classe1', 'Classe2a', 'Classe2b', 'Classe2c', 'Classe2d'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classificador perceptron pocket\n",
    "def perceptron_pocket(X, y, max_iter=1000, tol=1e-3):\n",
    "    \"\"\" Classificador perceptron pocket\n",
    "    Parâmetros\n",
    "    X : array-like, shape = [n_samples, n_features]\n",
    "        Conjunto de treinamento\n",
    "    y : array-like, shape = [n_samples]\n",
    "        Vetor de classes\n",
    "    max_iter : int, optional (default=1000)\n",
    "        Número máximo de iterações\n",
    "    tol : float, optional (default=1e-3)\n",
    "        Tolerância\n",
    "    Retorna\n",
    "    w_best : array-like, shape = [n_features]\n",
    "        Melhores pesos\n",
    "    \"\"\"\n",
    "\n",
    "    # Inicializa os pesos\n",
    "    w = np.zeros(X.shape[1])\n",
    "    # Inicializa o melhor w\n",
    "    w_best = w\n",
    "    # Inicializa o erro\n",
    "    error_best = np.sum(np.sign(X.dot(w_best)) != y)\n",
    "    # Inicializa o número de iterações\n",
    "    n_iter = 0\n",
    "    # Inicializa o erro\n",
    "    error = error_best\n",
    "    # Enquanto o erro for maior que a tolerância e o número de iterações for menor que o máximo\n",
    "    while error > tol and n_iter < max_iter:\n",
    "    # Para cada amostra de treinamento (x, y) em X e y\n",
    "        for x, y in zip(X, y):\n",
    "            # Se o sinal da predição for diferente do sinal da classe\n",
    "            if np.sign(x.dot(w)) != y:\n",
    "                # Atualiza os pesos\n",
    "                w = w + y * x\n",
    "                # Calcula o erro\n",
    "                error = np.sum(np.sign(X.dot(w)) != y)\n",
    "                # Se o erro for menor que o melhor erro\n",
    "                if error < error_best:\n",
    "                    # Atualiza o melhor erro\n",
    "                    error_best = error\n",
    "                    # Atualiza o melhor w\n",
    "                    w_best = w\n",
    "        # Incrementa o número de iterações\n",
    "        n_iter += 1\n",
    "    # Retorna o melhor w\n",
    "    return w_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classe1 = dados.get('Classe1')\n",
    "classe2 = dados.get('Classe2a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.69379038, 4.11338926, 4.12411209, 3.85291107, 4.46277413,\n",
       "        3.90842474, 4.55110928, 3.86055569, 4.89042697, 4.41114372,\n",
       "        3.77986131, 3.9187601 , 3.45737517, 3.03128939, 3.15613811,\n",
       "        4.00042265, 4.14323145, 4.34233247, 3.11195231, 3.30500127,\n",
       "        3.87035109, 4.23478034, 4.72773645, 4.81610441, 4.03399352,\n",
       "        4.11874114, 4.533364  , 4.83364254, 4.0102662 , 3.20150102,\n",
       "        4.17121825, 3.1659253 , 4.03395803, 4.87711573, 3.88126936,\n",
       "        4.31182764, 4.67939484, 4.10777413, 3.73437981, 4.15784698,\n",
       "        3.81355352, 3.88769167, 3.80277371, 3.80725733, 3.72089779,\n",
       "        3.52026039, 3.85879467, 3.59511077, 3.23841452, 4.41281446,\n",
       "        4.57014016, 3.78776685, 3.44135378, 3.37835934, 3.536152  ,\n",
       "        3.27729794, 4.80211581, 3.44236891, 3.75202223, 3.52974519,\n",
       "        3.87265415, 3.05221422, 3.86119304, 4.52482897, 4.36007728,\n",
       "        4.29025757, 3.43621746, 3.45605665, 4.78185764, 3.8048671 ,\n",
       "        4.21727086, 4.81819638, 3.66514281, 3.88479579, 3.06635881,\n",
       "        4.43299469, 3.67306585, 3.64385437, 4.0971326 , 4.10546427,\n",
       "        3.48300348, 3.3083189 , 4.87132275, 4.4565237 , 3.72074195,\n",
       "        3.00239679, 4.39923397, 4.08612435, 3.57485453, 4.52309237,\n",
       "        4.1521118 , 4.29106901, 4.00879572, 3.18429537, 3.3963394 ,\n",
       "        3.86302237, 3.51356913, 4.06456614, 4.89246031, 3.78536915],\n",
       "       [4.03398084, 3.31299044, 4.38960658, 4.67254084, 3.72006208,\n",
       "        3.7727798 , 4.46854221, 4.38750515, 4.5684652 , 3.21866848,\n",
       "        4.18180946, 3.10067997, 4.66837812, 4.72742173, 4.33808518,\n",
       "        3.4359876 , 3.2443783 , 4.1991711 , 3.11268604, 3.03924213,\n",
       "        4.66444295, 4.04025883, 3.19539584, 3.21603339, 3.28631204,\n",
       "        3.00915925, 4.69741845, 4.97393655, 3.54284325, 4.01569766,\n",
       "        4.52577419, 4.32319239, 3.34209604, 4.18096635, 4.88383786,\n",
       "        3.90389142, 4.065247  , 4.36013106, 3.47858121, 4.73377411,\n",
       "        3.22523028, 3.6003688 , 4.66672713, 3.78035188, 3.28051072,\n",
       "        3.1736302 , 3.51456557, 3.84971682, 3.99013385, 3.48714675,\n",
       "        3.14817915, 3.00678825, 3.00260114, 3.28496811, 3.34978413,\n",
       "        4.19777122, 4.87875953, 3.96534275, 4.04756007, 3.13671444,\n",
       "        3.34770607, 4.90935655, 4.92311715, 3.01469732, 4.41190151,\n",
       "        4.10461969, 4.54473243, 3.74172944, 4.71275382, 3.63603823,\n",
       "        4.82039045, 4.18318882, 4.70612726, 4.80871096, 4.06485297,\n",
       "        3.35860369, 3.3754259 , 3.80771342, 3.09747719, 3.54962281,\n",
       "        3.48629036, 4.91283272, 4.63742887, 3.35162346, 3.37757995,\n",
       "        3.63283903, 4.25051036, 3.87807441, 4.00331821, 4.5248161 ,\n",
       "        4.49532568, 3.24643904, 3.69452263, 3.29569894, 4.34454047,\n",
       "        4.38880782, 3.0195173 , 3.55878393, 4.81288653, 3.04971047]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classe2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_413367/2897906191.py:9: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  error_best = np.sum(np.sign(X.dot(w_best)) != y)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mperceptron_pocket\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclasse1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasse2\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [7], line 19\u001b[0m, in \u001b[0;36mperceptron_pocket\u001b[0;34m(X, y, max_iter, tol)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m error \u001b[38;5;241m>\u001b[39m tol \u001b[38;5;129;01mand\u001b[39;00m n_iter \u001b[38;5;241m<\u001b[39m max_iter:\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Para cada amostra de treinamento (x, y) em X e y\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(X, y):\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;66;03m# Se o sinal da predição for diferente do sinal da classe\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39msign(x\u001b[38;5;241m.\u001b[39mdot(w)) \u001b[38;5;241m!=\u001b[39m y:\n\u001b[1;32m     20\u001b[0m             \u001b[38;5;66;03m# Atualiza os pesos\u001b[39;00m\n\u001b[1;32m     21\u001b[0m             w \u001b[38;5;241m=\u001b[39m w \u001b[38;5;241m+\u001b[39m y \u001b[38;5;241m*\u001b[39m x\n\u001b[1;32m     22\u001b[0m             \u001b[38;5;66;03m# Calcula o erro\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "perceptron_pocket(classe1, classe2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
